{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b4699-7783-4355-b543-3dafc5e2a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject\n",
    "from shapely.geometry import Polygon\n",
    "from pystac_client import Client\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1fe32-5735-4920-8463-8832e44cd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "START_MONTH = \"2025-06\"\n",
    "END_MONTH = \"2025-07\"\n",
    "\n",
    "CITY = \"Toronto\"\n",
    "PROVINCE = \"Ontario\"\n",
    "COUNTRY = \"Canada\"\n",
    "\n",
    "OUTPUT_DIR = \"satellite_data\"\n",
    "CLOUD_COVERAGE_THRESHOLD = 30\n",
    "DOWNLOAD_TIMEOUT = 300\n",
    "MAX_WORKERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab08443-7c25-4261-8d92-022c0fe8bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDownloader:\n",
    "    def __init__(self, base_dir):\n",
    "        \"\"\"Initialize downloader for image-only processing\"\"\"\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.stac_client = Client.open(\"https://earth-search.aws.element84.com/v1\")\n",
    "        self.create_output_structure()\n",
    "        self.download_lock = threading.Lock()\n",
    "        self._session = None\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up session\"\"\"\n",
    "        if hasattr(self, '_session') and self._session:\n",
    "            self._session.close()\n",
    "    \n",
    "    def create_output_structure(self):\n",
    "        \"\"\"Create directory structure for images only\"\"\"\n",
    "        for satellite in ['sentinel1', 'sentinel2']:\n",
    "            (self.base_dir / \"raw\" / \"images\" / satellite).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def is_item_already_downloaded(self, item_id, satellite_type):\n",
    "        \"\"\"Check if item directory exists with files\"\"\"\n",
    "        image_dir = self.base_dir / \"raw\" / \"images\" / satellite_type / item_id\n",
    "        if not image_dir.exists():\n",
    "            return False\n",
    "        \n",
    "        # Quick check for essential files\n",
    "        if satellite_type == 'sentinel2':\n",
    "            essential_files = ['B02', 'B03', 'B04', 'B08']\n",
    "        else:\n",
    "            essential_files = ['VV', 'VH']\n",
    "        \n",
    "        for file_pattern in essential_files:\n",
    "            if not any(image_dir.glob(f\"{file_pattern}.*\")):\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def convert_s3_to_https(self, url):\n",
    "        \"\"\"Convert S3 URL to HTTPS\"\"\"\n",
    "        if url.startswith('s3://'):\n",
    "            s3_path = url[5:]\n",
    "            parts = s3_path.split('/', 1)\n",
    "            bucket = parts[0]\n",
    "            path = parts[1] if len(parts) == 2 else \"\"\n",
    "            return f\"https://{bucket}.s3.amazonaws.com/{path}\"\n",
    "        return url\n",
    "\n",
    "    def create_session(self):\n",
    "        \"\"\"Create optimized requests session\"\"\"\n",
    "        session = requests.Session()\n",
    "        \n",
    "        retry_strategy = Retry(\n",
    "            total=3,  # Reduced retries for speed\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "        )\n",
    "        \n",
    "        adapter = HTTPAdapter(\n",
    "            max_retries=retry_strategy,\n",
    "            pool_connections=20,  # Increased for concurrent downloads\n",
    "            pool_maxsize=20,\n",
    "            pool_block=True\n",
    "        )\n",
    "        \n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        session.headers.update({\n",
    "            'User-Agent': 'SatelliteDownloader/2.0',\n",
    "            'Accept': '*/*',\n",
    "            'Connection': 'keep-alive'\n",
    "        })\n",
    "        \n",
    "        return session\n",
    "\n",
    "    def download_file(self, url, output_path, max_retries=2):\n",
    "        \"\"\"Download file with minimal retries for speed\"\"\"\n",
    "        url = self.convert_s3_to_https(url)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Check if file already exists\n",
    "        if output_path.exists() and output_path.stat().st_size > 0:\n",
    "            return str(output_path)\n",
    "        \n",
    "        # Create session if needed\n",
    "        if not hasattr(self, '_session') or self._session is None:\n",
    "            self._session = self.create_session()\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                with self._session.get(url, stream=True, timeout=(15, 180)) as response:\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    with open(output_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=32768):  # Larger chunks\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                \n",
    "                if not output_path.exists() or output_path.stat().st_size == 0:\n",
    "                    raise ValueError(\"Downloaded file is empty\")\n",
    "                \n",
    "                return str(output_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                if output_path.exists():\n",
    "                    output_path.unlink()\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(1)  # Short wait\n",
    "                    if hasattr(self, '_session') and self._session:\n",
    "                        self._session.close()\n",
    "                        self._session = self.create_session()\n",
    "                else:\n",
    "                    return None\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def resample_to_10m(self, src_path, dst_path):\n",
    "        \"\"\"Fast resample to 10m resolution\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(src_path) as src:\n",
    "                scale_factor = src.res[0] / 10.0\n",
    "                new_width = int(src.width * scale_factor)\n",
    "                new_height = int(src.height * scale_factor)\n",
    "                \n",
    "                transform = src.transform * src.transform.scale(\n",
    "                    (src.width / new_width), (src.height / new_height)\n",
    "                )\n",
    "                \n",
    "                profile = src.profile.copy()\n",
    "                profile.update({\n",
    "                    'width': new_width,\n",
    "                    'height': new_height,\n",
    "                    'transform': transform,\n",
    "                    'compress': 'lzw',  # Add compression\n",
    "                    'tiled': True\n",
    "                })\n",
    "                \n",
    "                with rasterio.open(dst_path, 'w', **profile) as dst:\n",
    "                    for i in range(1, src.count + 1):\n",
    "                        reproject(\n",
    "                            source=rasterio.band(src, i),\n",
    "                            destination=rasterio.band(dst, i),\n",
    "                            src_transform=src.transform,\n",
    "                            src_crs=src.crs,\n",
    "                            dst_transform=transform,\n",
    "                            dst_crs=src.crs,\n",
    "                            resampling=Resampling.bilinear\n",
    "                        )\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def get_date_range_from_months(self, start_month, end_month):\n",
    "        \"\"\"Convert month strings to date range\"\"\"\n",
    "        start_year, start_month_num = map(int, start_month.split('-'))\n",
    "        end_year, end_month_num = map(int, end_month.split('-'))\n",
    "        \n",
    "        start_date = datetime(start_year, start_month_num, 1)\n",
    "        if end_month_num == 12:\n",
    "            end_date = datetime(end_year + 1, 1, 1)\n",
    "        else:\n",
    "            end_date = datetime(end_year, end_month_num + 1, 1)\n",
    "        \n",
    "        return start_date, end_date\n",
    "    \n",
    "    def get_city_polygon(self, city, province, country):\n",
    "        \"\"\"Get city bounding box from Nominatim API\"\"\"\n",
    "        try:\n",
    "            address = f\"{city}, {province}, {country}\"\n",
    "            response = requests.get(\n",
    "                \"https://nominatim.openstreetmap.org/search\",\n",
    "                params={'q': address, 'format': 'json', 'limit': 1},\n",
    "                headers={'User-Agent': 'SatelliteDownloader/2.0'},\n",
    "                timeout=15\n",
    "            )\n",
    "            \n",
    "            data = response.json()\n",
    "            if data and 'boundingbox' in data[0]:\n",
    "                bbox = data[0]['boundingbox']\n",
    "                return {\n",
    "                    'min_lat': float(bbox[0]), 'max_lat': float(bbox[1]),\n",
    "                    'min_lon': float(bbox[2]), 'max_lon': float(bbox[3])\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error with location lookup: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def query_stac_data(self, collection, start_date, end_date, bounds, max_cloud_cover=None):\n",
    "        \"\"\"Query STAC API for satellite data\"\"\"\n",
    "        bbox = [bounds['min_lon'], bounds['min_lat'], bounds['max_lon'], bounds['max_lat']]\n",
    "        \n",
    "        search_params = {\n",
    "            \"collections\": [collection],\n",
    "            \"datetime\": f\"{start_date.isoformat()}/{end_date.isoformat()}\",\n",
    "            \"bbox\": bbox,\n",
    "            \"limit\": 500  # Increased limit\n",
    "        }\n",
    "        \n",
    "        if max_cloud_cover is not None:\n",
    "            search_params[\"query\"] = {\"eo:cloud_cover\": {\"lt\": max_cloud_cover}}\n",
    "        \n",
    "        search = self.stac_client.search(**search_params)\n",
    "        items = list(search.items())\n",
    "        print(f\"   üì° {collection}: {len(items)} items found\")\n",
    "        \n",
    "        return items\n",
    "    \n",
    "    def filter_by_city_polygon(self, items, bounds):\n",
    "        \"\"\"Quick filter by area intersection\"\"\"\n",
    "        city_polygon = Polygon([\n",
    "            (bounds['min_lon'], bounds['min_lat']),\n",
    "            (bounds['max_lon'], bounds['min_lat']),\n",
    "            (bounds['max_lon'], bounds['max_lat']),\n",
    "            (bounds['min_lon'], bounds['max_lat']),\n",
    "            (bounds['min_lon'], bounds['min_lat'])\n",
    "        ])\n",
    "        \n",
    "        filtered_items = []\n",
    "        for item in items:\n",
    "            try:\n",
    "                bbox_coords = item.bbox\n",
    "                image_polygon = Polygon([\n",
    "                    (bbox_coords[0], bbox_coords[1]), (bbox_coords[2], bbox_coords[1]),\n",
    "                    (bbox_coords[2], bbox_coords[3]), (bbox_coords[0], bbox_coords[3]),\n",
    "                    (bbox_coords[0], bbox_coords[1])\n",
    "                ])\n",
    "                \n",
    "                if city_polygon.intersects(image_polygon):\n",
    "                    filtered_items.append(item)\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return filtered_items\n",
    "\n",
    "    def download_and_process_band(self, item, asset_name, band_name, output_dir, needs_resample=False):\n",
    "        \"\"\"Download and optionally resample a band\"\"\"\n",
    "        if asset_name not in item.assets:\n",
    "            return None\n",
    "        \n",
    "        asset_href = item.assets[asset_name].href\n",
    "        file_ext = '.jp2' if asset_href.endswith('.jp2') else '.tif'\n",
    "        \n",
    "        if needs_resample:\n",
    "            temp_path = output_dir / f\"{band_name}_temp{file_ext}\"\n",
    "            final_path = output_dir / f\"{band_name}.tif\"\n",
    "        else:\n",
    "            final_path = output_dir / f\"{band_name}{file_ext}\"\n",
    "            temp_path = None\n",
    "        \n",
    "        # Download file\n",
    "        download_path = temp_path if temp_path else final_path\n",
    "        if not self.download_file(asset_href, download_path):\n",
    "            return None\n",
    "        \n",
    "        # Resample if needed\n",
    "        if needs_resample and temp_path:\n",
    "            success = self.resample_to_10m(temp_path, final_path)\n",
    "            if temp_path.exists():\n",
    "                temp_path.unlink()  # Always cleanup temp file\n",
    "            if not success:\n",
    "                return None\n",
    "        \n",
    "        return str(final_path)\n",
    "    \n",
    "    def download_sentinel2_item(self, item):\n",
    "        \"\"\"Download essential Sentinel-2 bands only\"\"\"\n",
    "        try:\n",
    "            if self.is_item_already_downloaded(item.id, \"sentinel2\"):\n",
    "                return item.id\n",
    "            \n",
    "            image_dir = self.base_dir / \"raw\" / \"images\" / \"sentinel2\" / item.id\n",
    "            image_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Essential bands only for faster processing\n",
    "            essential_bands = {\n",
    "                'B02': (['B02', 'blue'], False),      # Blue - 10m\n",
    "                'B03': (['B03', 'green'], False),     # Green - 10m\n",
    "                'B04': (['B04', 'red'], False),       # Red - 10m\n",
    "                'B08': (['B08', 'nir'], False),       # NIR - 10m\n",
    "                'B11': (['B11', 'swir16'], True),     # SWIR - 20m->10m\n",
    "                'SCL': (['SCL', 'scl'], True)          # Scene Classification - 20m->10m\n",
    "            }\n",
    "            \n",
    "            downloaded_count = 0\n",
    "            \n",
    "            for band_name, (asset_names, needs_resample) in essential_bands.items():\n",
    "                asset_name = next((name for name in asset_names if name in item.assets), None)\n",
    "                if asset_name:\n",
    "                    result = self.download_and_process_band(item, asset_name, band_name, image_dir, needs_resample)\n",
    "                    if result:\n",
    "                        downloaded_count += 1\n",
    "            \n",
    "            # Need at least 4 essential bands\n",
    "            if downloaded_count >= 4:\n",
    "                return item.id\n",
    "            else:\n",
    "                # Clean up incomplete download\n",
    "                if image_dir.exists():\n",
    "                    for file in image_dir.iterdir():\n",
    "                        file.unlink()\n",
    "                    image_dir.rmdir()\n",
    "                return None\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def download_sentinel1_item(self, item):\n",
    "        \"\"\"Download Sentinel-1 VV and VH bands\"\"\"\n",
    "        try:\n",
    "            if self.is_item_already_downloaded(item.id, \"sentinel1\"):\n",
    "                return item.id\n",
    "            \n",
    "            image_dir = self.base_dir / \"raw\" / \"images\" / \"sentinel1\" / item.id\n",
    "            image_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            downloaded_count = 0\n",
    "            \n",
    "            # Download VV and VH polarizations\n",
    "            for pol in ['vv', 'vh']:\n",
    "                if pol in item.assets:\n",
    "                    result = self.download_and_process_band(item, pol, pol.upper(), image_dir)\n",
    "                    if result:\n",
    "                        downloaded_count += 1\n",
    "            \n",
    "            # Need both VV and VH\n",
    "            if downloaded_count >= 2:\n",
    "                return item.id\n",
    "            else:\n",
    "                # Clean up incomplete download\n",
    "                if image_dir.exists():\n",
    "                    for file in image_dir.iterdir():\n",
    "                        file.unlink()\n",
    "                    image_dir.rmdir()\n",
    "                return None\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def download_items_concurrently(self, items, download_func, satellite_name):\n",
    "        \"\"\"Download items with progress tracking\"\"\"\n",
    "        successful_downloads = []\n",
    "        total_items = len(items)\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            future_to_item = {executor.submit(download_func, item): item for item in items}\n",
    "            \n",
    "            completed = 0\n",
    "            for future in as_completed(future_to_item):\n",
    "                completed += 1\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result is not None:\n",
    "                        successful_downloads.append(result)\n",
    "                        with self.download_lock:\n",
    "                            print(f\"   ‚úÖ {satellite_name}: {len(successful_downloads)}/{completed} completed ({completed}/{total_items} processed)\")\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        return successful_downloads\n",
    "    \n",
    "    def download_satellite_data(self, start_month, end_month, city, province, country):\n",
    "        \"\"\"Main download function - images only\"\"\"\n",
    "        try:\n",
    "            start_date, end_date = self.get_date_range_from_months(start_month, end_month)\n",
    "            bounds = self.get_city_polygon(city, province, country)\n",
    "            \n",
    "            if not bounds:\n",
    "                raise ValueError(f\"Could not find bounds for {city}, {province}, {country}\")\n",
    "            \n",
    "            print(f\"üõ∞Ô∏è  Downloading satellite data for {city}, {province}, {country}\")\n",
    "            print(f\"üìÖ Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"üöÄ Using {MAX_WORKERS} concurrent workers\")\n",
    "            print(f\"üéØ Mode: Images only (no metadata)\")\n",
    "            \n",
    "            # Query satellite data\n",
    "            print(\"\\nüîç Querying satellite catalogs...\")\n",
    "            s1_items = self.query_stac_data(\"sentinel-1-grd\", start_date, end_date, bounds)\n",
    "            s2_items = self.query_stac_data(\"sentinel-2-l2a\", start_date, end_date, bounds, CLOUD_COVERAGE_THRESHOLD)\n",
    "            \n",
    "            # Filter by location\n",
    "            print(\"üåç Filtering by location...\")\n",
    "            s1_filtered = self.filter_by_city_polygon(s1_items, bounds)\n",
    "            s2_filtered = self.filter_by_city_polygon(s2_items, bounds)\n",
    "            \n",
    "            print(f\"üìä After filtering: {len(s1_filtered)} S1 + {len(s2_filtered)} S2 items\")\n",
    "            \n",
    "            # Download concurrently\n",
    "            print(\"\\n‚¨áÔ∏è  Starting downloads...\")\n",
    "            \n",
    "            s1_successful = []\n",
    "            s2_successful = []\n",
    "            \n",
    "            if s1_filtered:\n",
    "                print(f\"üõ∞Ô∏è  Downloading Sentinel-1 items...\")\n",
    "                s1_successful = self.download_items_concurrently(s1_filtered, self.download_sentinel1_item, \"S1\")\n",
    "            \n",
    "            if s2_filtered:\n",
    "                print(f\"üõ∞Ô∏è  Downloading Sentinel-2 items...\")\n",
    "                s2_successful = self.download_items_concurrently(s2_filtered, self.download_sentinel2_item, \"S2\")\n",
    "            \n",
    "            # Final summary\n",
    "            print(f\"\\nüéâ Download complete!\")\n",
    "            print(f\"üìä Results:\")\n",
    "            print(f\"   üõ∞Ô∏è  Sentinel-1: {len(s1_successful)}/{len(s1_filtered)} items downloaded\")\n",
    "            print(f\"   üõ∞Ô∏è  Sentinel-2: {len(s2_successful)}/{len(s2_filtered)} items downloaded\")\n",
    "            print(f\"üìÅ Images saved to: {self.base_dir}/raw/images/\")\n",
    "            print(f\"üöÄ Ready for processing!\")\n",
    "            \n",
    "            return {\n",
    "                'sentinel1_downloaded': len(s1_successful),\n",
    "                'sentinel2_downloaded': len(s2_successful),\n",
    "                'total_downloaded': len(s1_successful) + len(s2_successful)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in download process: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09806e-157e-4b71-8ac2-16398a3dc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"    \n",
    "    try:\n",
    "        print(f\"üöÄ Satellite Data Downloader\")\n",
    "        print(f\"üìç Location: {CITY}, {PROVINCE}, {COUNTRY}\")\n",
    "        print(f\"üìÖ Date range: {START_MONTH} to {END_MONTH}\")\n",
    "        print(f\"‚òÅÔ∏è  Max cloud cover: {CLOUD_COVERAGE_THRESHOLD}%\")\n",
    "        \n",
    "        # Create downloader and run\n",
    "        downloader = SatelliteDownloader(OUTPUT_DIR)\n",
    "        summary = downloader.download_satellite_data(START_MONTH, END_MONTH, CITY, PROVINCE, COUNTRY)\n",
    "        \n",
    "        print(\"\\n‚úÖ Download completed successfully!\")\n",
    "        print(f\"üìÇ Input structure created: {OUTPUT_DIR}/raw/images/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in main execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39fed2-3301-4c6e-ac6e-4cd87ab69703",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
